import argparse
import json
import sys
import os
from pathlib import Path
from typing import Optional
from qa_agent.llm.chatgpt import ChatGPTLLM
from qa_agent.agents.base import BaseAgent
from qa_agent.core.registry import register_agent


#### ë‚˜ì¤‘ì— ê°œë°œì sdkë¡œ ëº´ê¸°!!
def create_prompt_agent(name: str, description: str, input_keys: list, output_key: str, prompt_template: str, save_path: Optional[str] = None):
    
    def build_prompt(self, code: str) -> str:
        # inputì´ stringì¸ ê²½ìš°ë¥¼ ìƒì •
        return prompt_template.format(code=code)

    def run(self, state: dict) -> dict:
        code = state.get("input", "")
        if not code:
            raise ValueError("ì…ë ¥ stateì— 'input' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

        prompt = self.build_prompt(code)
        response = self.llm.generate(prompt) if self.llm else "[ì‘ë‹µ ì—†ìŒ]: LLMì„ ì„¤ì •í•´ì£¼ì„¸ìš”."
        state[output_key] = response
        return state

    def run_with_input(self, code: str) -> str:
        return self.run({"input": code})[output_key]

    AgentClass = type(
        f"{name.title().replace('_', '')}Agent",
        (BaseAgent,),
        {
            "name": name,
            "description": description,
            "input_keys": ["input"],  # LangGraphì™€ ì¼ê´€ì„± ìˆê²Œ
            "output_keys": [output_key],
            "build_prompt": build_prompt,
            "run": run,
            "run_with_input": run_with_input,
        }
    )

    register_agent(name, AgentClass)
    
    if save_path:
        save_prompt_agent(
            path=save_path,
            name=name,
            description=description,
            input_keys=input_keys,
            output_key=output_key,
            prompt_template=prompt_template
        )
        print("Saved your Agent!")

def save_prompt_agent(path: str, **kwargs):
    config = {
        "type": "agent",
        **kwargs
    }
    Path(path).write_text(json.dumps(config, indent=2, ensure_ascii=False), encoding="utf-8")
    
def load_prompt_aget(path: str):
    config = json.loads(Path(path).read_text(encoding="utf-8"))

    if config.get("type") != "agent":
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” Agent íƒ€ì…ì…ë‹ˆë‹¤.")

    create_prompt_agent(
        name=config["name"],
        description=config["description"],
        input_keys=config["input_keys"],
        output_key=config["output_key"],
        prompt_template=config["prompt_template"]
    )
    

################################################

def load_llm(model: str, model_type: str):
    if model == "chatgpt":
        if not os.environ.get("OPENAI_API_KEY"):
            raise EnvironmentError("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return ChatGPTLLM(model=model_type)
    else:
        raise NotImplementedError(f"LLM model {model} is not supported yet.")
    
def load_input(args) -> dict:
    if args.input:
        return json.loads(args.input)
    elif args.file:
        input = Path(args.file).read_text(encoding="utf-8")
        return {"input": input}
    elif not sys.stdin.isatty():
        # í‘œì¤€ì…ë ¥ ì²˜ë¦¬
        input = sys.stdin.read()
        return {"input": input}
    else:
        raise ValueError("ì…ë ¥ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. --input, --file, stdin ì¤‘ í•˜ë‚˜ëŠ” í•„ìš”í•©ë‹ˆë‹¤.")

def print_result(args, result):
    if getattr(args, "output", None):
        Path(args.output).write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding="utf-8")
        print(f"âœ… ê²°ê³¼ ì €ì¥ë¨: {args.output}")

    if getattr(args, "summary_only", False):
        print("\nğŸ“‹ ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸ (qa_report):\n")
        print(result.get("qa_report", "[ìš”ì•½ ë¦¬í¬íŠ¸ ì—†ìŒ]"))
    elif not getattr(args, "output", None):
        print("\nğŸ“‹ ì „ì²´ ê²°ê³¼:")
        for k, v in result.items():
            print(f"\n[{k}]\n{v}")
            



def resolve_input(input_val) -> dict:
    if isinstance(input_val, dict):
        return input_val
    elif isinstance(input_val, str):
        path = Path(input_val)
        if path.exists():
            content = path.read_text(encoding="utf-8")
            try:
                return json.loads(content)  # jsonì´ë©´ dictë¡œ
            except json.JSONDecodeError:
                return {"input": content}    # ì•„ë‹ˆë©´ ê·¸ëƒ¥ ì½”ë“œ ë¬¸ìì—´
        else:
            return {"input": input_val}      # ê·¸ëƒ¥ ë¬¸ìì—´ ì½”ë“œë¡œ ê°„ì£¼
    else:
        raise ValueError("inputì€ str ë˜ëŠ” dict íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")


# def save_result(result, output_path, output_name='result.json'):
#     Path(output_path).write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding="utf-8")
#     print(f"âœ… ê²°ê³¼ ì €ì¥ë¨: {output_path}")